{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import datasets\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-11T12:26:20.578659Z","iopub.execute_input":"2021-10-11T12:26:20.579426Z","iopub.status.idle":"2021-10-11T12:26:20.591450Z","shell.execute_reply.started":"2021-10-11T12:26:20.579375Z","shell.execute_reply":"2021-10-11T12:26:20.590270Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#baca data\ndata = pd.read_table('/kaggle/input/data-diabet/datadiabet.tab.txt')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:26:20.594045Z","iopub.execute_input":"2021-10-11T12:26:20.594353Z","iopub.status.idle":"2021-10-11T12:26:20.623919Z","shell.execute_reply.started":"2021-10-11T12:26:20.594319Z","shell.execute_reply":"2021-10-11T12:26:20.622890Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"## memberikan informasi tentang tipe data, kolom, jumlah nilai nol, penggunaan memori, dll\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:26:23.901864Z","iopub.execute_input":"2021-10-11T12:26:23.902064Z","iopub.status.idle":"2021-10-11T12:26:23.916085Z","shell.execute_reply.started":"2021-10-11T12:26:23.902039Z","shell.execute_reply":"2021-10-11T12:26:23.915109Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"## cetak grafik untuk korelasi\nplt.figure(figsize=(8,8))\nplt.title('Korelasi antara variabel dataset')\nsns.heatmap(df.corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:26:23.917749Z","iopub.execute_input":"2021-10-11T12:26:23.918060Z","iopub.status.idle":"2021-10-11T12:26:24.862153Z","shell.execute_reply.started":"2021-10-11T12:26:23.918022Z","shell.execute_reply":"2021-10-11T12:26:24.861133Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Yang kita lihat adalah korelasi antara data.\n\nData dengan nilai yang sangat positif atau negatif memiliki korelasi yang lebih kuat.\n\nMisalnya S1 dan S2 keduanya meningkat dan memiliki korelasi positif di antara keduanya, yang mungkin membuatnya mubazir untuk mempertahankan keduanya. S3 dan S4 juga berkaitan erat, karena memiliki nilai korelasi yang mendekati -1. Ketika yang satu bertambah, yang lain berkurang.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n#memisahkan label dari target\nX = data.drop('Y', axis=1)\ny = data.Y\n\n#membagi data menjadi rangkaian percobaan dan pengujian\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=9) #test_size is for the size of test set","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:26:24.863738Z","iopub.execute_input":"2021-10-11T12:26:24.864027Z","iopub.status.idle":"2021-10-11T12:26:24.873179Z","shell.execute_reply.started":"2021-10-11T12:26:24.863996Z","shell.execute_reply":"2021-10-11T12:26:24.872406Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"dilanjutkan untuk membuat regresi linier. Model ini tidak membutuhkan penskalaan.","metadata":{}},{"cell_type":"code","source":"#membuat objek Linear Regresi\n\nregr = LinearRegression()\n\n#percobaan model dengan set percobaan\n\nregr.fit(X_train, y_train)\n\n#membuat prediksi menggunakan set \n\npred = regr.predict(X_test)\n\n#Koefisien determinasi: 1 adalah prediksi sempurna\nprint('Koefisien determinasi: %.2f' % r2_score(y_test, pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:26:24.874525Z","iopub.execute_input":"2021-10-11T12:26:24.874749Z","iopub.status.idle":"2021-10-11T12:26:24.889747Z","shell.execute_reply.started":"2021-10-11T12:26:24.874723Z","shell.execute_reply":"2021-10-11T12:26:24.888779Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Saya menggunakan hyperparameter r2_score untuk mengevaluasi model ML saya. Skor R2 adalah metrik yang memberi tahu saya jika model saya bagus, semakin dekat nilainya dengan 1. Dalam hal ini r2 adalah 0,59, jadi model itu bagus untuk membuat prediksi.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, KFold\n\nkf= KFold(n_splits=10)#cross validation \n\n#scaling data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n#defining parameters\nparameters = {'n_estimators':[100], #[10,20,50,100,200],\n              'max_features': ['auto'],\n              'max_samples': [9], #[2,3,4,6,7,8,9],\n              'max_depth': [5], #[2,3,4,5,6,7,8,9],\n             }\n\nrf=RandomForestRegressor()\ngs = GridSearchCV(rf,parameters, cv=5) #validation for Random Forest\n\ngs.fit(X_train, y_train)\nrf=gs.best_estimator_\nprint(rf)\n\nrfpred = gs.predict(X_test)\n\nprint('R2: %.2f' %r2_score(y_test, rfpred))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:26:24.890754Z","iopub.execute_input":"2021-10-11T12:26:24.891018Z","iopub.status.idle":"2021-10-11T12:26:25.937458Z","shell.execute_reply.started":"2021-10-11T12:26:24.890992Z","shell.execute_reply":"2021-10-11T12:26:25.936565Z"},"trusted":true},"execution_count":34,"outputs":[]}]}